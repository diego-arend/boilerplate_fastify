# Worker Module - Background Job Processing

Sistema de workers separados para processamento assÃ­ncrono de jobs com **MongoDB â†’ Redis â†’ BullMQ** flow.

## ğŸ—ï¸ **Architecture**

### **Container Separation**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Container â”‚    â”‚   Redis Queue   â”‚    â”‚ Worker Containerâ”‚
â”‚  (Publisher)    â”‚â”€â”€â”€â–¶â”‚    (BullMQ)     â”‚â”€â”€â”€â–¶â”‚   (Consumer)    â”‚
â”‚ WORKER_MODE=falseâ”‚    â”‚                 â”‚    â”‚ WORKER_MODE=trueâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 StandaloneWorker                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  1ï¸âƒ£ MongoDB (JobBatchRepository)                    â”‚
â”‚      â†“ loadNextBatch()                              â”‚
â”‚      â†“ Busca jobs pendentes                         â”‚
â”‚                                                      â”‚
â”‚  2ï¸âƒ£ Redis Queue (QueueManager)                      â”‚
â”‚      â†“ addJob() para cada job                       â”‚
â”‚      â†“ Adiciona jobs no BullMQ                      â”‚
â”‚                                                      â”‚
â”‚  3ï¸âƒ£ BullMQ Worker Processing                        â”‚
â”‚      â†“ JOB_HANDLERS[jobType](data, jobId, ...)     â”‚
â”‚      â†“ Processa job com handler especializado       â”‚
â”‚                                                      â”‚
â”‚  4ï¸âƒ£ MongoDB Update                                  â”‚
â”‚      â†“ markJobAsCompleted() ou markJobAsFailed()   â”‚
â”‚      âœ… Atualiza status final                       â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Files Structure**

```
src/infraestructure/workers/
â”œâ”€â”€ worker.ts      # ğŸ­ StandaloneWorker class
â”œâ”€â”€ index.ts       # ğŸš€ Worker entry point
â””â”€â”€ README.md      # ğŸ“– This documentation
```

## âš™ï¸ **Environment Variables**

### **Critical Parameters**

```env
# Container Mode
WORKER_MODE=true               # Enable worker mode

# Batch Control (Performance Critical)
BATCH_SIZE_JOBS=50             # MongoDB â†’ Redis batch size
WORKER_SIZE_JOBS=10            # BullMQ worker concurrency
WORKER_PROCESSING_INTERVAL=5000 # Batch loading interval (ms)

# Connection
QUEUE_NAME=app-queue
MONGO_URI=mongodb://mongo:27017/app
QUEUE_REDIS_HOST=redis
QUEUE_REDIS_DB=1
```

### **Environment Files**

```
.env.worker.development    # Development settings
.env.worker.production     # Production settings
```

## ğŸš€ **Usage**

### **Development**

```bash
# Start full environment
pnpm run docker:dev

# Worker logs
docker logs boilerplate_fastify-worker-dev-1 -f

# Worker health check
curl http://localhost:3003/health
```

### **Production**

```bash
# Start production
pnpm run docker:prod

# Scale workers
docker-compose up --scale worker=3

# Monitor workers
docker stats
```

### **Standalone Worker**

```bash
# Local development
WORKER_MODE=true pnpm run worker:dev

# Direct execution
node dist/infraestructure/workers/index.js
```

## ğŸ”§ **Configuration**

### **Performance Tuning**

#### **Development Settings**

```env
BATCH_SIZE_JOBS=25     # Smaller batches for debugging
WORKER_SIZE_JOBS=5     # Limited workers for resources
WORKER_PROCESSING_INTERVAL=3000  # Faster for testing
```

#### **Production Settings**

```env
BATCH_SIZE_JOBS=100    # Larger batches for throughput
WORKER_SIZE_JOBS=20    # More workers for parallelization
WORKER_PROCESSING_INTERVAL=5000  # Optimized interval
```

### **Resource Limits**

```yaml
# docker-compose.yml
worker:
  deploy:
    resources:
      limits:
        cpus: '0.8'
        memory: 768M
      reservations:
        cpus: '0.3'
        memory: 256M
```

## ğŸ¯ **Worker Flow**

### **Processing Cycle**

1. **Batch Loading**: MongoDB â†’ Redis (every `WORKER_PROCESSING_INTERVAL`)
2. **Job Processing**: Redis â†’ BullMQ Workers (concurrent: `WORKER_SIZE_JOBS`)
3. **Status Update**: Results â†’ MongoDB
4. **Error Handling**: Failed jobs â†’ Dead Letter Queue

### **StandaloneWorker Class**

```typescript
class StandaloneWorker {
  // Core methods for developers
  async run(); // Start worker process
  async stop(); // Graceful shutdown
  async getStats(); // Performance metrics
  async healthCheck(); // Container health

  // Internal methods
  private loadBatchToRedis(); // MongoDB â†’ Redis loading
  private registerJobHandlers(); // BullMQ job registration
}
```

## ğŸ“Š **Monitoring**

### **Health Check**

```bash
# Worker health endpoint
curl http://localhost:3003/health
# Returns: { status: "ok", uptime: 3600, ... }
```

### **Performance Metrics**

```typescript
const stats = await worker.getStats();
// Returns:
// {
//   worker: { config, isRunning, batchLoading },
//   jobs: { pending, processing, completed, failed },
//   queue: { waiting, active, completed, failed },
//   connections: { mongo: true, redis: true }
// }
```

### **Bull Dashboard**

- **URL**: http://localhost:3002/ui
- **Features**: Real-time monitoring, job management, retry controls

## ğŸ”„ **Job Processing**

### **Supported Job Types**

Workers automatically process all registered job types:

- `email:send` - Email sending
- `user:notification` - User notifications
- `data:export` - Data exports
- `file:process` - File processing
- `cache:warm` - Cache warming

### **Error Handling**

- **Automatic Retry**: Exponential backoff with configurable attempts
- **Failure Callbacks**: Automatic MongoDB status updates
- **Dead Letter Queue**: Failed jobs tracking and analysis

## ï¿½ **Scaling**

### **Horizontal Scaling**

```bash
# Scale workers at runtime
docker-compose up --scale worker=5

# Update compose file for permanent scaling
# Edit docker-compose.yml:
worker:
  deploy:
    replicas: 3
```

### **Performance Optimization**

```env
# High throughput setup
BATCH_SIZE_JOBS=200
WORKER_SIZE_JOBS=50

# Memory constrained setup
BATCH_SIZE_JOBS=25
WORKER_SIZE_JOBS=5
```

## ğŸ§ª **Development**

### **Local Testing**

```bash
# Test worker compilation
pnpm run build

# Test worker startup
WORKER_MODE=true NODE_ENV=development node dist/infraestructure/workers/index.js

# Integration test
pnpm run docker:dev
```

### **Debugging**

```bash
# Worker container access
docker-compose exec worker bash

# Check worker logs
docker-compose logs worker -f

# Monitor resources
docker-compose top worker
```

## ğŸ” **Troubleshooting**

### **Common Issues**

**Worker not processing jobs:**

```bash
# Check Redis connection
docker-compose logs redis

# Verify worker mode
echo $WORKER_MODE  # Should be 'true'
```

**High memory usage:**

```bash
# Reduce batch size
BATCH_SIZE_JOBS=25

# Reduce worker concurrency
WORKER_SIZE_JOBS=5
```

**Jobs piling up:**

```bash
# Increase worker concurrency
WORKER_SIZE_JOBS=20

# Scale worker containers
docker-compose up --scale worker=3
```
